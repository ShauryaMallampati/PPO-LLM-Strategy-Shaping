{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15a6b972",
   "metadata": {},
   "source": [
    "# ðŸ³ PPO-LLM Strategy Shaping: Setup & Configuration\n",
    "\n",
    "**Run this notebook first** to set up the environment before running any other notebooks.\n",
    "\n",
    "## What this does:\n",
    "- Installs required dependencies\n",
    "- Sets up Overcooked-AI environment\n",
    "- Mounts Google Drive for saving results\n",
    "- Defines shared configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb70155",
   "metadata": {},
   "source": [
    "## Step 1: Clone Overcooked-AI Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5dfd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content\n",
    "\n",
    "# Get a clean fresh copy of the HumanCompatibleAI overcooked repo\n",
    "!rm -rf overcooked_ai\n",
    "!git clone --depth 1 https://github.com/HumanCompatibleAI/overcooked_ai.git /content/overcooked_ai > /dev/null\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(\"/content/overcooked_ai/src\")\n",
    "\n",
    "print(\"CWD:\", os.getcwd())\n",
    "print(\"overcooked_ai in path:\", \"/content/overcooked_ai/src\" in sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df50f7c",
   "metadata": {},
   "source": [
    "## Step 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c01d5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q gym \"stable-baselines3[extra]\" overcooked-ai transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f86865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix NumPy compatibility (run this cell, then restart runtime)\n",
    "!pip uninstall -y numpy\n",
    "!pip install numpy==1.26.4\n",
    "\n",
    "import os\n",
    "os._exit(0)  # Forces runtime restart - RE-RUN CELLS ABOVE after this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7d6622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add shimmy for stable-baselines3 + gym compatibility\n",
    "!pip install -q \"shimmy>=2.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb221dd5",
   "metadata": {},
   "source": [
    "## Step 3: Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9b0e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\", force_remount=True)\n",
    "\n",
    "import os, zipfile\n",
    "\n",
    "DRIVE_ROOT = \"/content/drive/MyDrive\"\n",
    "print(\"Contents of MyDrive:\", os.listdir(DRIVE_ROOT))\n",
    "\n",
    "# Prefer the already-unzipped runs folder if it exists\n",
    "RUNS_ROOT = os.path.join(DRIVE_ROOT, \"runs\")\n",
    "\n",
    "# If runs folder is not there but runs.zip is, unzip once\n",
    "if (not os.path.exists(RUNS_ROOT)) and os.path.exists(os.path.join(DRIVE_ROOT, \"runs.zip\")):\n",
    "    print(\"Unzipping runs.zip into MyDrive...\")\n",
    "    with zipfile.ZipFile(os.path.join(DRIVE_ROOT, \"runs.zip\"), \"r\") as zf:\n",
    "        zf.extractall(DRIVE_ROOT)\n",
    "\n",
    "print(\"Using RUNS_ROOT:\", RUNS_ROOT, \"exists:\", os.path.exists(RUNS_ROOT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110d8b9a",
   "metadata": {},
   "source": [
    "## Step 4: Shared Configuration\n",
    "\n",
    "These values are used across all notebooks. Modify here to change experiment settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e2b8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from overcooked_ai_py.mdp.actions import Action\n",
    "\n",
    "# ==========================================\n",
    "# SHARED CONFIGURATION - EDIT HERE\n",
    "# ==========================================\n",
    "\n",
    "# Environment settings\n",
    "LAYOUT = \"asymmetric_advantages\"  # Options: \"cramped_room\", \"asymmetric_advantages\", \"coordination_ring\"\n",
    "HORIZON = 400  # Episode length\n",
    "\n",
    "# Hardware\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Experiment seeds for reproducibility\n",
    "SEEDS = [1001, 2002, 3003, 4004, 5005]\n",
    "\n",
    "# Training settings\n",
    "CHECKPOINT_EVERY_STEPS = 50_000\n",
    "LOG_EVERY_STEPS = 2_048\n",
    "EVAL_EPISODES = 10\n",
    "\n",
    "# File paths\n",
    "RESULTS_CSV = \"/content/drive/MyDrive/results_combined_new.csv\"\n",
    "RUNS_DIR = \"/content/drive/MyDrive/runs\"\n",
    "\n",
    "# LLM reward shaping\n",
    "LLM_BONUS = 0.2\n",
    "LLM_MODEL_NAME = \"EleutherAI/gpt-neo-1.3B\"  # or \"EleutherAI/gpt-neo-125M\" for faster\n",
    "\n",
    "# Training steps per baseline\n",
    "BASELINE_STEPS = {\n",
    "    \"Baseline\": 1_000_000,\n",
    "    \"CC_PPO\":   1_000_000,\n",
    "    \"SP_PPO\":   1_000_000,\n",
    "    \"HARL\":     1_000_000,\n",
    "    \"PPO+LLM\":  600_000,   # LLM shaping requires fewer steps!\n",
    "    \"PBT_PPO\":  1_000_000,\n",
    "}\n",
    "\n",
    "# Baselines and environments to test\n",
    "BASELINES = [\"Baseline\", \"PPO+LLM\", \"CC_PPO\", \"SP_PPO\", \"HARL\", \"PBT_PPO\"]\n",
    "ENV_NAMES = [\"No Noise\", \"Noise\", \"Delay\", \"Combo\"]\n",
    "\n",
    "# Derived\n",
    "NUM_ACTIONS = len(Action.ALL_ACTIONS)\n",
    "\n",
    "print(\"\\nâœ… Configuration loaded!\")\n",
    "print(f\"Layout: {LAYOUT}\")\n",
    "print(f\"Baselines: {BASELINES}\")\n",
    "print(f\"Environments: {ENV_NAMES}\")\n",
    "print(f\"Seeds: {SEEDS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c637c8f9",
   "metadata": {},
   "source": [
    "## âœ… Setup Complete!\n",
    "\n",
    "You can now run other notebooks:\n",
    "- **02_training.ipynb** - Train all baselines\n",
    "- **03_nash_analysis.ipynb** - Nash gap analysis\n",
    "- **04_latency_analysis.ipynb** - Measure inference latency\n",
    "- **05_robustness_analysis.ipynb** - Test robustness to perturbations\n",
    "- **06_task_completion.ipynb** - Evaluate task completion metrics"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
