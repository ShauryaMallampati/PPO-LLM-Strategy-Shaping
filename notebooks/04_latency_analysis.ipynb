{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ead768b6",
   "metadata": {},
   "source": [
    "# 04 - Latency Analysis\n",
    "\n",
    "Measures per-step decision latency (in milliseconds) for all trained models.\n",
    "\n",
    "**Output:** `/content/drive/MyDrive/latency_results.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c7ee77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "from overcooked_ai_py.mdp.overcooked_env import OvercookedEnv, OvercookedGridworld\n",
    "from overcooked_ai_py.mdp.actions import Action\n",
    "\n",
    "# =========================================================\n",
    "# 0. CONFIG (MATCH TRAINING)\n",
    "# =========================================================\n",
    "try:\n",
    "    RUNS_DIR\n",
    "except NameError:\n",
    "    RUNS_DIR = \"/content/drive/MyDrive/runs\"\n",
    "\n",
    "try:\n",
    "    LAYOUT\n",
    "except NameError:\n",
    "    LAYOUT = \"asymmetric_advantages\"\n",
    "\n",
    "try:\n",
    "    DEVICE\n",
    "except NameError:\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "HORIZON = 400\n",
    "NUM_ACTIONS = len(Action.ALL_ACTIONS)\n",
    "\n",
    "BASELINES  = [\"Baseline\", \"PPO+LLM\", \"CC_PPO\", \"SP_PPO\", \"HARL\", \"PBT_PPO\"]\n",
    "ENV_NAMES  = [\"No Noise\", \"Noise\", \"Delay\", \"Combo\"]\n",
    "SEEDS      = [1001, 2002, 3003, 4004, 5005]\n",
    "\n",
    "LATENCY_CSV = \"/content/drive/MyDrive/latency_results.csv\"\n",
    "\n",
    "# =========================================================\n",
    "# 1. ENVIRONMENT WRAPPERS (TRUE 2-AGENT, MATCH TRAIN ENV)\n",
    "# =========================================================\n",
    "class OCWrapper(gym.Env):\n",
    "    \"\"\"\n",
    "    True 2-agent Overcooked wrapper:\n",
    "    - observation: global featurized state (flattened)\n",
    "    - action_space: MultiDiscrete([NUM_ACTIONS, NUM_ACTIONS])\n",
    "    - reward: shared team reward\n",
    "    \"\"\"\n",
    "    metadata = {\"render.modes\": []}\n",
    "\n",
    "    def __init__(self, layout):\n",
    "        super().__init__()\n",
    "        mdp = OvercookedGridworld.from_layout_name(layout)\n",
    "        self.oc = OvercookedEnv.from_mdp(mdp, horizon=HORIZON)\n",
    "\n",
    "        o0, _ = self.oc.featurize_state_mdp(self.oc.state)\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=-np.inf,\n",
    "            high=np.inf,\n",
    "            shape=o0.flatten().shape,\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        self.action_space = gym.spaces.MultiDiscrete([NUM_ACTIONS, NUM_ACTIONS])\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "            np.random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.manual_seed_all(seed)\n",
    "        self.oc.reset()\n",
    "        o0, _ = self.oc.featurize_state_mdp(self.oc.state)\n",
    "        return o0.flatten().astype(np.float32), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        a0, a1 = int(action[0]), int(action[1])\n",
    "        joint = [Action.ALL_ACTIONS[a0], Action.ALL_ACTIONS[a1]]\n",
    "        state, r, done, info = self.oc.step(joint)\n",
    "        o0, _ = self.oc.featurize_state_mdp(state)\n",
    "        return o0.flatten().astype(np.float32), float(r), bool(done), False, info\n",
    "\n",
    "\n",
    "class OCWrapperNoise(OCWrapper):\n",
    "    def step(self, action):\n",
    "        obs, r, term, trunc, info = super().step(action)\n",
    "        obs = (obs + np.random.normal(0, 0.01, size=obs.shape)).astype(np.float32)\n",
    "        return obs, r, term, trunc, info\n",
    "\n",
    "\n",
    "class OCWrapperDelay(OCWrapper):\n",
    "    def __init__(self, layout, noise_prob=0.2, delay_penalty=0.5):\n",
    "        super().__init__(layout)\n",
    "        self.noise_prob = noise_prob\n",
    "        self.delay_penalty = delay_penalty\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, r, term, trunc, info = super().step(action)\n",
    "        if np.random.rand() < self.noise_prob:\n",
    "            r -= self.delay_penalty\n",
    "        return obs, r, term, trunc, info\n",
    "\n",
    "\n",
    "class OCWrapperCombo(OCWrapper):\n",
    "    def __init__(self, layout, noise_prob=0.2, delay_penalty=0.5):\n",
    "        super().__init__(layout)\n",
    "        self.noise_prob = noise_prob\n",
    "        self.delay_penalty = delay_penalty\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, r, term, trunc, info = super().step(action)\n",
    "        obs = (obs + np.random.normal(0, 0.01, size=obs.shape)).astype(np.float32)\n",
    "        if np.random.rand() < self.noise_prob:\n",
    "            r -= self.delay_penalty\n",
    "        return obs, r, term, trunc, info\n",
    "\n",
    "\n",
    "def make_env(env_name: str, layout: str):\n",
    "    \"\"\"\n",
    "    Evaluation env factory (same mapping as training make_env).\n",
    "    No LLM shaping, no HARL shaping: pure environment dynamics.\n",
    "    \"\"\"\n",
    "    e = env_name.lower()\n",
    "    mapping = {\n",
    "        \"no noise\": OCWrapper,\n",
    "        \"noise\": OCWrapperNoise,\n",
    "        \"delay\": OCWrapperDelay,\n",
    "        \"combo\": OCWrapperCombo,\n",
    "    }\n",
    "    return Monitor(mapping[e](layout))\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 2. CORE MEASUREMENT: ms PER DECISION STEP\n",
    "# =========================================================\n",
    "def measure_step_latency(agent, env, episodes=5):\n",
    "    \"\"\"\n",
    "    Measures average latency per decision step (predict + env.step),\n",
    "    in milliseconds.\n",
    "    \"\"\"\n",
    "    total_time = 0.0\n",
    "    total_steps = 0\n",
    "\n",
    "    for _ in range(episodes):\n",
    "        obs, _ = env.reset()\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            t0 = time.perf_counter()\n",
    "\n",
    "            # Decision + transition\n",
    "            action, _ = agent.predict(obs, deterministic=True)\n",
    "            obs, r, term, trunc, _ = env.step(action)\n",
    "\n",
    "            t1 = time.perf_counter()\n",
    "\n",
    "            total_time += (t1 - t0)\n",
    "            total_steps += 1\n",
    "            done = term or trunc\n",
    "\n",
    "    if total_steps == 0:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    # seconds → milliseconds\n",
    "    return (total_time / total_steps) * 1000.0\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 3. LOAD MODEL AND MEASURE LATENCY\n",
    "# =========================================================\n",
    "def load_and_measure_latency(baseline, env_name, seed, episodes=5):\n",
    "    \"\"\"\n",
    "    Loads a trained PPO model from:\n",
    "      RUNS_DIR/<baseline>/<env>/seed_<seed>/final_model.zip\n",
    "    builds the matching env with make_env, and measures latency.\n",
    "    \"\"\"\n",
    "    safe_base = baseline.replace(\" \", \"_\")\n",
    "    safe_env  = env_name.replace(\" \", \"_\")\n",
    "\n",
    "    model_path = f\"{RUNS_DIR}/{safe_base}/{safe_env}/seed_{seed}/final_model.zip\"\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"[WARN] Missing model: {model_path}\")\n",
    "        return None\n",
    "\n",
    "    env = make_env(env_name, LAYOUT)\n",
    "\n",
    "    agent = PPO.load(model_path, env=env, device=DEVICE)\n",
    "\n",
    "    # Warmup passes (stabilize GPU / cache effects)\n",
    "    for _ in range(10):\n",
    "        obs, _ = env.reset()\n",
    "        action, _ = agent.predict(obs, deterministic=True)\n",
    "        obs, _, term, trunc, _ = env.step(action)\n",
    "        if term or trunc:\n",
    "            break\n",
    "\n",
    "    latency_ms = measure_step_latency(agent, env, episodes=episodes)\n",
    "    print(f\"{baseline} | {env_name} | seed={seed}: {latency_ms:.4f} ms/step\")\n",
    "\n",
    "    return latency_ms\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 4. SWEEP ALL MODELS AND WRITE CSV\n",
    "# =========================================================\n",
    "def run_latency_sweep():\n",
    "    \"\"\"\n",
    "    For every (baseline, env, seed), measure latency and write:\n",
    "      baseline, env, seed, latency_ms\n",
    "    Then also write per (baseline, env) mean and std at the bottom.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    print(\"=== Measuring per-step latency for all models ===\")\n",
    "    for b in BASELINES:\n",
    "        for e in ENV_NAMES:\n",
    "            seed_latencies = []\n",
    "            for s in SEEDS:\n",
    "                lat = load_and_measure_latency(b, e, s, episodes=5)\n",
    "                if lat is not None and not np.isnan(lat):\n",
    "                    rows.append([b, e, s, lat])\n",
    "                    seed_latencies.append(lat)\n",
    "\n",
    "            if seed_latencies:\n",
    "                mean_lat = float(np.mean(seed_latencies))\n",
    "                std_lat  = float(np.std(seed_latencies))\n",
    "                print(f\"[AGG] {b} | {e}: {mean_lat:.4f} ± {std_lat:.4f} ms/step\")\n",
    "                rows.append([b, e, \"mean_over_seeds\", mean_lat])\n",
    "                rows.append([b, e, \"std_over_seeds\", std_lat])\n",
    "\n",
    "    os.makedirs(os.path.dirname(LATENCY_CSV), exist_ok=True)\n",
    "    with open(LATENCY_CSV, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"baseline\", \"env\", \"seed_or_stat\", \"latency_ms\"])\n",
    "        writer.writerows(rows)\n",
    "\n",
    "    print(f\"\\nLatency sweep complete. Saved to: {LATENCY_CSV}\")\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 5. ENTRY POINT\n",
    "# =========================================================\n",
    "if __name__ == \"__main__\":\n",
    "    run_latency_sweep()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
